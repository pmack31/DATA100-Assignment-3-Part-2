---
title: "Exploration of Happiness and Climate Change"
subtitle: "Exploring Disparate Data: Part 3 - Final Report"
author: "Old Souls"
date: "Due November 26th, 2025"
output: pdf_document
---

List your group members, including their student numbers, here:

-   Peter MacKenzie (169139553)
-   Frank Castiglione (169079592)
-   Josh Di Maulo (169112454)

The purpose of this investigation is to establish whether world happiness and climate change awareness (and meteorological data - tropical cyclone intensity) is linked by establishing that a happy world is one in which climate change is often acknowledged more and often acknowledged more by those whom live in conditions often enough that they acknowledge their conditions changing intensity.
The intention is to combine three seemingly disparate sets of data - the World Happiness Report (2023), The Climate Change Opinion Survey (2022) and the NOAA cyclone data 1851-2022 to establish whether a correlation exists between socioemotional trends of a globalized world and the world in which it lives which may denote a need for interdisciplinary connection and awareness going forward.
General findings of exploratory data analysis show that cyclone intensity is regionally different - average maximum wind speed (73.54 mph) shows an increase since 2000 for the 21st century in Atlantic cyclones as a significant increase however, Eastern Pacific storms have less variability than average. Furthermore, climate change awareness is country specific, but climate change awareness is highest in a European nation (marginally effective than all others) but worlds average significantly lower than top responding nations. Furthermore, the most compelling finding between world happiness and climate change awareness is that there is a slight positive correlation between the two. This denotes that it's not the negatives about climate change that frustrate people, but instead, those who are more aware and engaged on various levels happens to find themselves in countries where their wealth and perceived assistance/institutional assistance is more likely to support national levels of happiness.
Whereas all of this data suggests a pattern of globalization, an inverted, more complex pattern emerges with the environmental and social metrics. Future studies may include economic realities, policy examinations, and institutional development to gauge a more causal relationship behind this interdisciplinary relationship between humane engagement and the world and humankind.


# Data Description
In this report, the analysis determined will prove the impact in relationships between happiness of nations, climate change knowledge and environment. These are three international datasets constructed for different purposes, but have a valuable connection between them. The datasets provide varying lenses as to how a population experiences and understands climate change, meaning that by comparing data sets, nations with higher levels of awareness and attention to climate change feel better or worse overall. The first dataset used is a study from the National Hurricane Center, noting cyclones over time with comparison to storm occurrence, strength and locations across locations near oceans. The second dataset is a recent Climate Change Opinion Survey from 2022 which generalizes climate change knowledge in over 100 countries. Lastly, the third data set comes from the World Happiness Report from 2023, which is a more recent data set ranking nations based on social, economic, and institutional considerations. By bringing these sources together, this will help provide a better understanding of a globalized perspective where environmental circumstances, climate change literacy and happiness operate on intersecting planes. Ultimately, this report recognizes growing global patterns and understands how climate conditions and perceptions might otherwise relate to national wellness.
```{r}
knitr::opts_chunk$set(error = TRUE)
library(tidyverse)
theme_set(theme_bw())
library(arrow)
library(openxlsx)
library(ggplot2)
library(countrycode)
```

## \<\<Cyclones\>\>

```{r load_data1}

# Set the base URL for NOAA cyclone data
cyclone_data_address <- "https://www.nhc.noaa.gov/data/hurdat/"
# Define filenames for Atlantic and Northeast Pacific cyclone datasets
at_cyclone_filename <- "hurdat2-1851-2022-050423.txt"
np_cyclone_filename <- "hurdat2-nepac-1949-2022-050423.txt"

# Define column names for the detailed observation data that will be parsed
new_columns <- c("status", "latitude", "longitude", "max_wind",
    "min_pressure", "NE_extend_34", "SE_extend_34", "SW_extend_34",
    "NW_extend_34", "NE_extend_50", "SE_extend_50", "SW_extend_50",
    "NW_extend_50", "NE_extend_64", "SE_extend_64", "SW_extend_64",
    "NW_extend_64", "r_max_wind"
)

#Process Atlantic cyclone data
at_cyclone <- str_c(cyclone_data_address, at_cyclone_filename, sep = "") |>
  # Read the CSV file with temporary column names (1-4)  
  read_csv(
        col_names = c(as.character(1:4)),
        progress = FALSE,
        show_col_types = FALSE
    ) |>
  # Split the 4th column into multiple columns
    separate_wider_delim(
        cols = `4`,
        # Set the delim and the names
        delim = ",",
        names = new_columns
    ) |>
  #Data cleaning
    mutate(
      # Remove whitespace from all columns
        across(everything(), str_trim),
        # Convert missing values to NA
        across(everything(), ~na_if(., "-999")),
        across(everything(), ~na_if(., "-99")),
        # Create storm data columns
        BasinNumberYear = ifelse(is.na(status), `1`, NA),
        Name = ifelse(is.na(status), `2`, NA),
        Entries = ifelse(is.na(status), `3`, NA)
    ) |>
  # Reorganize columns to put data first
    relocate(BasinNumberYear, Name, Entries) |>
  # Fill down data values to observation rows for each storm
    fill(BasinNumberYear, Name, Entries) |>
  # Remove header rows, keeping only observation rows
    filter(!is.na(status))  |>
  # Remove the Entries column as it is no longer needed
    select(-Entries) |>
  # Split BasinNumberYear into its components
    separate_wider_position(
        BasinNumberYear,
        widths = c(
        Basin = 2,   # Basin code
        Number = 2,  # Storm number for the year
        NameYear = 4 # Year of the storm
        )
    ) |>
  # Split date information from column 1
    separate_wider_position(
        `1`,
        widths = c(
        ObservYear = 4,  # Observation year
        Month = 2,       # Observation month
        Day = 2          # Observation day
        )
    ) |>
  # Split time information from column 2
    separate_wider_position(
        `2`,
        widths = c(
          Hour = 2,    # Observation hour
          Minute = 2   # Observation minute
        )
    ) |>
  # Rename column 3 to more better name
    rename(
        Identifier = `3`   # Record identifier
    ) |>
  # Convert character columns to integers
    mutate(
        across(
            c(NameYear, ObservYear, Month, Day, Hour,
                Minute, Number),
            as.integer
        )
    ) |>
  # Convert measurement columns to numeric
    mutate(across(max_wind:r_max_wind, as.numeric))

# Process Northeast Pacific cyclone data using the same steps as above
np_cyclone <- str_c(cyclone_data_address, np_cyclone_filename, sep = "") |>
    # ALL of the steps all over again
    read_csv(
        col_names = c(as.character(1:4)),
        progress = FALSE,
        show_col_types = FALSE
    ) |>
    separate_wider_delim(
        cols = `4`,
        # Set the delim and the names
        delim = ",",
        names = new_columns
    ) |>
    mutate(
        across(everything(), str_trim),
        # make "-999" NAs, make "-99" NAs
        # Create columns BasinNumberYear, Name, and Entries
        across(everything(), ~na_if(., "-999")),
        across(everything(), ~na_if(., "-99")),
        BasinNumberYear = ifelse(is.na(status), `1`, NA),
        Name = ifelse(is.na(status), `2`, NA),
        Entries = ifelse(is.na(status), `3`, NA)
    ) |>
    relocate(BasinNumberYear, Name, Entries) |>
    fill(BasinNumberYear, Name, Entries) |>
    filter(!is.na(status))  |>
    select(-Entries) |>
    separate_wider_position(
        BasinNumberYear,
        # Specify the widths
        widths = c(
        Basin = 2,
        Number = 2,
        NameYear = 4
        )
    ) |>
    separate_wider_position(
        `1`,
        # Specify the widths
        widths = c(
        ObservYear = 4,
        Month = 2,
        Day = 2
        )
    ) |>
    separate_wider_position(
        `2`,
        # Specify the widths
        widths = c(
          Hour = 2,
          Minute = 2
        )
    ) |>
    rename(
        Identifier = `3`
    ) |>
    mutate(
        across(
            c(NameYear, ObservYear, Month, Day, Hour,
                Minute, Number),
            as.integer
        )
    ) |>
    mutate(across(max_wind:r_max_wind, as.numeric))

# Combine Atlantic and Pacific data into a single dataset
cyclones_data_update_0 <- bind_rows(at_cyclone, np_cyclone)

# Helper function to convert latitude/longitude from string to numeric
# Handles directions by applying negative sign for W and S
convert_latlon <- function(latlon) {
    parse_number(latlon) * if_else(str_detect(latlon, "[WS]"), -1, 1
  )
}

# Apply coordinate conversion
cyclones_data_update_1 <- cyclones_data_update_0 |>
    mutate(
        lat = convert_latlon(latitude),   # Convert latitude to numeric
        lon = convert_latlon(longitude)   # Convert longitude to numeric
    )

# Create proper datetime column from date/time components
cyclones_data_update_2 <- cyclones_data_update_1 |>
    mutate(
        date = make_datetime(ObservYear, Month, Day, Hour, Minute)
    )

# Define category levels for hurricane classification
cat_levels <- c("TD", "TS", "1", "2", "3", "4", "5")

# Assign hurricane categories based on maximum wind speed
cyclones_data <- cyclones_data_update_2 |>
    mutate(
        category = ordered(
            case_when(
                (max_wind <= 33) ~ "TD",  # Tropical Depression
                (max_wind <= 63) ~ "TS",  # Tropical Storm
                (max_wind <= 82) ~ "1",   # Category 1 Hurricane
                (max_wind <= 95) ~ "2",   # Category 2 Hurricane
                (max_wind <= 112) ~ "3",  # Category 3 Hurricane
                (max_wind <= 136) ~ "4",  # Category 4 Hurricane
                (max_wind >= 137) ~ "5"   # Category 5 Hurricane
                ),
            levels = cat_levels # set levels as ordered factor
        )
    )

# save as parquet
write_parquet(cyclones_data, sink = "cyclones_data.parquet")

# Note that the code in this document will not be shown
# when you click "knit", so the placement of this code
# chunk is purely for your benefit: You can see what happened
# with your data, which makes it easier to describe below!
```

The data come from \<<place>\> and describe \<<more specific description of the data>\>.

In order to clean the data, we \<\<steps to clean the data, concise but precise enough that a reader could follow your steps without seeing your code\>\>.

## \<\<Climate Change\>\>

```{r load_data2}
# Set URL for climate opinion survey dataset
climate_opinion_address <- "https://data.humdata.org/dataset/dc9f2ca4-8b62-4747-89b1-db426ce617a0/resource/6041db5f-8190-47ff-a10b-9841325de841/download/climate_change_opinion_survey_2022_aggregated.xlsx"

# Get the names of all sheets in the Excel workbook
climate_sheet_names <- climate_opinion_address |>
    loadWorkbook() |>
    names()

# Define the sheet name we want to work with
aware_sheet_name <- "climate_awareness"

# Process the climate awareness data
climate_awareness <- climate_opinion_address |>
  # Read the sheet from the Excel file
    read.xlsx(
        sheet = aware_sheet_name
    ) |>
    # Transform the data from wide to long
    # Keep the climate_awareness column as is, pivot all other columns
    pivot_longer(
        cols = !contains(aware_sheet_name),  # Select all columns except "climate_awareness"
        names_to = "country",  # Column names become values in new "country" column
        values_to = "score"    # Cell values become values in new "score" column
    ) |>
  # Clean and standardize the response categories
    mutate(
        climate_awareness = case_when(
          # Convert responses to concise, standardized codes
            climate_awareness == "I have never heard of it" ~ "aware_no",
            climate_awareness == "I know a little about it" ~ "aware_alittle",
            climate_awareness == "I know a moderate amount about it" ~
                "aware_moderate",
            climate_awareness == "I know a lot about it" ~ "aware_alot",
            climate_awareness == "Refused" ~ "aware_refuse",
            climate_awareness == "(Unweighted Base)" ~ "aware_base"
        )
    ) |>
  # Rename the main categorical column to "answer"
    rename(answer = climate_awareness) |>
  # Transform back to wide format with response categories as separate columns
    pivot_wider(
        names_from = answer,
        values_from = score
    )

# Save the processed data in parquet format
write_parquet(climate_awareness, "climate_awareness.parquet")

# Reminder: do NOT print your data to the screen unless it's
# completely necessary
```

The data comes from \<\<the Climate Change Opinion Survey in 2022, including more than 100 countries' citizens, who gave valuable information about awareness and changes in their attitude towards climate change. The results prove that human activities are a major contributor to climate change. In Latin America, Europe, and on small island nations, the majority of citizens have a high level of concern about climate change. It is believed that in the next 20 years, climate change will cause harm to both current citizens and future generations. To solve this issue, the majority of concern lies with governments and businesses, but many individuals say they would also take action if necessary. It is seen to have support to transition toward renewable energy and transition away from fossil fuels to reduce harm caused towards climate change, and the data reflects that climate change is human-caused and requires immediate, collective action.\>\>.

In order to clean the data, we \<\<first access the Humanitarian Data Exchange public file that is the public dataset and then provides the file path to access the workbook directly. The loadWorkbook() function is then initiated to determine the sheet names within the recognized excel workbook. Then the sheet name climate_awareness is extracted from this list to proceed with the remainder of file access and reshaping concerning the dataset. The read.xlsx() function reads the relevant sheet of the excel workbook into R and the pivot_longer() function reshapes the file from wide to long, taking country column names and creating a new variable name "country", while keeping "climate_awareness" as is for the categorical variable. This crossjoins each uniquely-response category with different country's scores. For example, one response category might be "I know a little about it" and this will appear on separate rows for separate countries with different scores. Therefore, in order to make response categories more manageable, the mutate() and case_when() functions are used in conjunction to re-code long survey responses into shorter response codes. For example, "I know a little about it" is now re-coded to aware_alittle. Similar adjustments were made for other response categories. After this re-coding, the main column is renamed from “climate_awareness” to “answer” to bring clarity and consistency. The dataset is then changed back to wide format using pivot_wider(), which will create separate columns for each category with their respective scores. Finally, the cleaned and transformed data is exported and saved in Parquet format using write_parquet(), which allows storage and compatibility for future analysis.\>\>

## \<\<Happiness\>\>

```{r load_data3}
# read excel fie containing the happiness data
happiness <- read.xlsx("DataForTable2.1.xlsx") |>
  #clean column names
    janitor::clean_names() |>
  #rename "country_name" to "country" for consistency
    rename(country = country_name) |>
  #remove rows with missing happiness scores
    filter(!is.na(ladder_score)) |>
  #group data by country to process each country separately
    group_by(country) |>
  #sort years in descending order within each country
    arrange(desc(year)) |>
    #slice to get most recent observation
    slice(1) |>
  #remove grouping for future operations
    ungroup()

```

The data comes from \<\<the World Happiness Report 2023, explaining that global wellbeing is assessed in an additional 150 countries through surveys like Gallup World Poll. They additionally clarify how happiness is assessed through social support, freedom of choices in life, perceived corruption, life expectancy and GDP per capita. They assert that on a national level, social support and institutional credibility and social networks/community/group endeavors increase happiness averages. Furthermore, they assert income with social equity best sustains happiness over time as economic growth shows increased income is insufficient when simultaneously assessed for inequality and fear. Furthermore, the report assesses regional averages with regional means which show the Nordic countries at the top time and again as they are highly assessed in trustworthy and governmental abilities. Furthermore, a consistent theme is resilience in assessments as researchers assess countries that either maintained happiness or reduced their numbers amid international shocks (shock being defined as pandemic, financial crisis or geopolitical conflict). Finally, in 2023, a consistent shift in data has occurred post-pandemic assessing psychological recovery or simple aging (decline). Finally, the appendices show the value of country-to-country comparisons as well as over time for researchers with statistical validity and additional statistical assessments and credibility.\>\> and detail \<<more specific description of the data>\>.

In order to clean the data, we \<\<The following R code loads and cleans the World Happiness Report dataset from the Excel document DataForTable2.1.xlsx. To begin, the read.xlsx() function reads the unedited excel document into R as is. Then, for purposes of easier transformations, janitor::clean_names() functions to make all column titles lower case, replace spaces with underscores, and eliminate special characters. The third aspect of this function renames the country_name title to country in order to maintain title uniformity amongst the various World Happiness Report excel documents and provides clearer referencing for analyses further down the road. Lastly, the code omits missing values from the ladder_score column by using the filter() function to exclude these scores. Once such actions are taken, the dataset is grouped by country using group_by(country) so that subsequent analyses can take place one country at a time. Once grouped, the dataset is sorted with arrange(desc(year)), which allows each country’s observations to be ordered from the most recent year to the oldest year. Finally, the ungroup() function is used to remove the current grouping, ensuring that future moves apply to the dataset as a whole rather than within each country.\>\>

## Combining the Data

Explain how any combinations of data were performed. Explain what kind of join was needed, whether columns had to be modified (for example, matching "country" names.)

# Exploratory Data Analysis

To achieve our goals, we explored the data by...

We explored many aspects of the data, but will demonstrate three. These are \<\<Cyclone intensity patterns reveal diverging trends between ocean basins, with Atlantic storms showing increased average wind speeds since 2000 while Eastern Pacific storms remain relatively stable, suggesting regional climate variations may influence tropical cyclone behavior differently across geographic areas.\>\>, \<\<Climate awareness levels vary dramatically across nations, with European countries (Germany, UK) showing 40-50% of respondents reporting high climate knowledge compared to less than 25% in some Asian nations, indicating that geography, education systems, and media exposure may significantly shape public understanding of climate change.\>\>, and \<<National happiness scores show a weak positive correlation with climate awareness across continents, suggesting that higher climate knowledge does not necessarily diminish life satisfaction; instead, countries with greater awareness (primarily in Europe) tend to maintain high happiness levels, potentially due to stronger social support systems and environmental policies that mitigate climate anxiety.>\>

The first aspect that we found interesting is shown in \@ref(fig:insight1). The insight should be specific to the data shown, not a general statement beyond the data (leave that for the conclusion).

```{r insight1, fig.cap="Average cyclone intensity by basin from 2000-2022, showing trends in maximum wind speeds. Point size indicates the number of storms recorded each year. The dashed red line marks the hurricane threshold (64 knots), with smooth trend lines revealing diverging patterns between Atlantic (AL) and Eastern Pacific (EP) basins."}

plot1_data <- cyclones_data |>
  mutate(year = year(date)) |>
  filter(year >= 2000, !is.na(max_wind)) |>
  group_by(year, Basin) |>
  summarize(
    avg_max_wind = mean(max_wind, na.rm = TRUE),
    storm_count = n(),
    .groups = 'drop'
  )

plot1 <- ggplot(plot1_data, aes(x = year, y = avg_max_wind, color = Basin)) +
  geom_point(aes(size = storm_count), alpha = 0.6) +
  geom_smooth(method = "loess", se = TRUE, linewidth = 1) +
  scale_size_continuous(name = "Storm Count", range = c(2, 8)) +
  scale_color_manual(
    values = c("AL" = "salmon", "EP" = "skyblue"),
    labels = c("AL" = "Atlantic", "EP" = "E. Pacific")
  ) +
  labs(
    title = "Hurricane Intensity Trends by Basin (2000-2022)",
    subtitle = "Point size represents number of storms recorded",
    x = "Year",
    y = "Average Maximum Wind Speed (knots)",
    color = "Basin"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    legend.position = "bottom"
  )
plot1

# This is an example of how you can control figures and captions in
# an R chunk. Note that you can reference figures using:
# \@ref(fig:insight1), where "insight1" is the label of this code
# chunk (the first bit of text after the "r" in "```{r label, options...}")

```

This insight is supported by the summary statistics in table \@ref(tab:summary_stats)

```{r summary_stats}
# Calculate the relevant summary statistics here.
# Note that the "kable" function in the "knitr" package
# is convenient for making nice tables. Other packages can
# do much fancier things with tables, but keep in mind that
# the insights should be the star, not the formatting.

# Prepare happiness data with continent classification
happiness_recent <- happiness |>
  group_by(country) |>
  slice_max(year, n = 1) |>
  ungroup() |>
  select(country, ladder_score, year) |>
  mutate(
    # Add continent using countrycode package
    continent = countrycode(
      sourcevar = country,
      origin = "country.name",
      destination = "continent"
    )
  )

# Prepare climate awareness composite score
climate_composite <- climate_awareness |>
  mutate(
    awareness_score = (
      coalesce(aware_alot, 0) * 3 + 
      coalesce(aware_moderate, 0) * 2 + 
      coalesce(aware_alittle, 0) * 1
    ) / 100  # Normalize to 0-3 scale
  ) |>
  select(country, awareness_score)

# Join the datasets
combined_data <- happiness_recent |>
  inner_join(climate_composite, by = "country") |>
  filter(!is.na(awareness_score), !is.na(ladder_score), !is.na(continent))

# Create summary statistics table by continent
summary_stats <- combined_data |>
  group_by(continent) |>
  summarize(
    n_countries = n(),
    avg_happiness = round(mean(ladder_score, na.rm = TRUE), 2),
    sd_happiness = round(sd(ladder_score, na.rm = TRUE), 2),
    avg_awareness = round(mean(awareness_score, na.rm = TRUE), 2),
    sd_awareness = round(sd(awareness_score, na.rm = TRUE), 2),
    .groups = 'drop'
  ) |>
  arrange(desc(avg_happiness))

# Display the table
knitr::kable(
  summary_stats,
  col.names = c("Continent", "N Countries", "Mean Happiness", "SD Happiness", 
                "Mean Awareness", "SD Awareness"),
  caption = "Summary Statistics: Happiness and Climate Awareness by Continent"
)
```

The next insight that we found is shown in \@ref(fig:insight2).

```{r insight2, fig.height=4, fig.width=6, fig.cap="Distribution of climate change awareness levels across eight major nations, faceted by country. Responses range from 'Never Heard' (red) to 'A Lot' (green), revealing substantial cross-national variation in public climate knowledge. European nations show higher proportions of strong awareness compared to other regions."}
# This figure will have a height of 4 and a width of 6.
# Feel free to change this, and to apply different sizes
# to the other figures you create.

# Select top countries by population/representation and prepare data
top_countries <- c("United.States", "Israel", "India", "Brazil", 
                   "United.Kingdom", "Germany", "Japan", "Australia")

plot2_data <- climate_awareness |>
  filter(country %in% top_countries) |>
  select(country, aware_no, aware_alittle, aware_moderate, aware_alot) |>
  pivot_longer(
    cols = starts_with("aware_"),
    names_to = "awareness_level",
    values_to = "percentage"
  ) |>
  filter(!is.na(percentage)) |>
  mutate(
    awareness_level = factor(
      awareness_level,
      levels = c("aware_no", "aware_alittle", "aware_moderate", "aware_alot"),
      labels = c("Never Heard", "A Little", "Moderate", "A Lot")
    ),
    region = case_when(
      country %in% c("United States", "Brazil") ~ "Americas",
      country %in% c("United Kingdom", "Germany") ~ "Europe",
      country %in% c("Israel", "India", "Japan", "Australia") ~ "Asia-Pacific"
    )
  )

plot2 <- ggplot(plot2_data, aes(x = awareness_level, y = percentage, fill = awareness_level)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ country, ncol = 4) +
  scale_fill_manual(values = c(
    "Never Heard" = "salmon",
    "A Little" = "orange",
    "Moderate" = "yellow",
    "A Lot" = "springgreen"
  )) +
  labs(
    title = "Climate Change Awareness Levels Across Major Nations",
    subtitle = "Survey responses showing knowledge distribution",
    x = "Awareness Level",
    y = "Percentage of Respondents (%)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
    strip.text = element_text(face = "bold")
  )

print(plot2)

```

Finally, \@ref(fig:insight3) shows ...

```{r insight3, fig.height=4, fig.width=6, fig.cap="Relationship between national happiness scores (World Happiness Report) and climate awareness scores (Climate Opinion Survey 2022), combining two distinct datasets. Points are colored by continent, with the regression line suggesting a slight positive correlation between climate knowledge and national well-being across many countries."}

plot3 <- ggplot(combined_data, aes(x = awareness_score, y = ladder_score)) +
  geom_point(aes(color = region), size = 3, alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE, color = "black", linewidth = 1.2) +
  scale_color_brewer(palette = "Set2", name = "Region") +
  labs(
    title = "National Happiness vs Climate Change Awareness",
    subtitle = "Examining the relationship between climate knowledge and well-being",
    x = "Climate Awareness Score (0-3 scale)",
    y = "Happiness Score (Ladder Score)",
    caption = "Sources: World Happiness Report & Climate Opinion Survey 2022"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    legend.position = "bottom",
    legend.title = element_text(face = "bold")
  )

print(plot3)

```

# Conclusion and Future Work

Overall, we found \<<general ideas>\>.

A second paragraph about our findings.

The next steps in this analysis are...

The limitations of this analysis are as follows. (Do not simply list potential issues with sampling, but relate them to your analysis and how they affect your conclusions. An honest and complete acknowledgement of the limitations makes the analysis more trustworthy.)

# References

I am not strict about MLA or APA style or anything like that. For this report, I would much rather have your citations be easy to match to your insights.

The easiest way is to use Rmd's [footnote](https://bookdown.org/yihui/rmarkdown/markdown-syntax.html#inline-formatting) syntax. This will put a number beside the word where the footnote appears, and the full text of the footnote at the bottom of the page (pdf) or end of the document (html). The syntax is:[^1], where I suggest that you put in something like this[^2] to make references for this assignment.
https://joss.theoj.org/papers/10.21105/joss.01686 
https://cran.r-project.org/web/packages/countrycode/index.html 
https://cran.r-project.org/web/packages/knitr/knitr.pdf 
[^1]: See the source view to see this footnote

[^2]: The relevance to the insight is ... . From \<<name of source and name of article>\>, published on \<<date>\>, url: \<<link to page>\>

Alternatively, you could make a list of citations with their main arguments and why they're relevent to your insights, methods, etc.

The link above also references "bibtex" files. These are also extremely convenient, but have a steep learning curve and they make it difficult to tie them to an insight. If you use bibtext, then make sure that you provide a sentence to describe the source and it's relevance when you cite it - don't just add citations to the end of a sentence (this is common practice in academia, but I want to know that your citations are directly relevant for this assignmnet).
